---
layout: page
subheadline:  "image detection"
title:  "VGGNet"
teaser: ""
categories:
    - machine learning
    - deep learning
tags:
    - machine learning
    - deep learning
    - image detection
header: no
---

- ILSVRC-2014에서 localization 1등, classification 2등한 모델이다. (1등은 GoogleNet)

1. Introduction
논문에서 주로 ConvNet의 구조 중 depth에 대해서 다룰 것이라고 소개한다.

2. ConvNet configurations
  - Architecture
  224X224 RGB 이미지를 input으로 받고, training시 전처리는 subtracting mean만 해준다.
  filter의 구조는 3X3과 1X1만 사용하고 stride도 전부다 1로 spatial resolution이 보존되게 하였다.
  spatial pooling의 경우는 max-pooling 때 되도록 하였으며 2X2 pixel window에 stride 2를 사용하였다.
  convolutional layer 뒤에 FC layer가 3개 존재하고 앞서 봤던 모델의 구조와 같다.
  앞의 2개 layer는 4096개 channel을 갖고 마지막 layer에서 softmax 진행되며 class의 개수인 1000개 channel만 남는다.
  앞서 AlexNet에서 사용했던 Local Response Normalization은 실험 후 성능에 효과가 없다고 판단되어 사용하지 않는다.

  - Configurations
  아래 그림의 table1에 논문에서 비교하려는 모델들의 구조가 나타나있다. 전체적인 기본 디자인은 전부다 같으며 depth의 차이가 난다.
  table2에서는 parameter수가 모델 별로 나타나 있는데 가장 기본이 되는 11-layer 구조와 19-layer의 parameter수가
  별 차이가 나지 않는 것을 볼 수 있는데 이는 parameter의 경우 FC layer에 어차피 거의 집중되어 있어서 그런듯하다.
  ![table1,2](http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/img/vggModel.jpg)

  - Discussion
  AlexNet에서 11X11, stride 4, ZFNet에서 7X7, stride 2를 첫번째 layer에서 사용한 것과 달리 VGGNet에서는
  3X3 receptive field만 사용하며 3X3의 반복을 통해 5X5, 7X7의 동일한 효과를 낼 수 있다고 말한다.
  그럼 이렇게 했을 때 이점이 있을까? 그렇다.
  첫번째로 ReLu layer가 추가되면서 non-linearity가 증가하고 decision function을 discriminative하게 만든다고 한다.
  두번째는 parameter수가 줄어든다.
  마찬가지의 이유로 1X1 layer도 사용되는데 receptive field에 영향을 주지 않으면서 non-linearity를 증가시킬 수 있다.
  GoogleNet과 마찬가지로 [Network in Network - Lin et al.](https://arxiv.org/pdf/1312.4400.pdf)에서 사용한 것을 보고
  영향을 받았다고 한다.

3. Classification framework
  - Training
  training 방법은 AlexNet이랑 거의 유사하게 진행되었으며 batch size 256, momentum 0.9, dropout 0.5,
  weight decay, learning rate 0.01(val set accuracy 증가 멈추면 10씩 감소) 등의 조건으로 수행했다.
  training은 총 74 epoch 동안 진행되었고 이는 AlexNet보다 더 적게 소요된 것이라고 한다. 이렇게 적은 epoch에도
  training 할 수 있었던 이유는 깊은 망, 작은 conv filter에 의한 implicit regularization 효과와 pre-initialization 때문이라고 한다.
  깊은 망일수록 initialization이 중요한데 VGGNet에서는 pre-training으로 해결하였다. 11-layer 모델을 먼저 random initialization(mean 0, variance 0.01)
  하여 충분히 학습시킨 후에 이를 다른 모델을 학습시킬 때 활용하엿다.

  - Training image size
  이미지 augmentation을 위한 crop size는 224X224로 정해져있으며(input size) crop하는 대상은 원본의 rescaled된 이미지이다.
  여기서 rescaled할 때 어떤 크기로 하느냐가 매우 중요한데, 크게하면 crop했을 때 부분만 표현되게 할 수 있고, 작게하면 전체 이미지가
  전부 표현되게 되기 때문이다. VGGNet에서는 두가지 방법을 택해서 사용하고 있다.
  첫번째는 scale을 254, 384 두가지로 고정하여 사용하는 방법이고 두번째는 [256, 512] 크기 사이에서 random sampling해서 가져오는 방법이다.
  training 속도 문제를 해결하기 위해 두 방법 모두 pre-training을 진행하였다.

  - Testing
  



Reference: <br>
 Simonyan, Karen, and Andrew Zisserman. ["Very deep convolutional networks for large-scale image recognition."](https://arxiv.org/pdf/1409.1556.pdf) arXiv preprint arXiv:1409.1556 (2014)
